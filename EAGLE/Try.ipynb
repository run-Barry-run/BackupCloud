{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71cf287b-de40-4ee7-8e67-3c7f19846cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/hxl/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home1/hxl/disk/EAGLE/eagle/model/multimodal_encoder/vision_models/convnext.py:1015: UserWarning: Overwriting convnext_xxlarge in registry with eagle.model.multimodal_encoder.vision_models.convnext.convnext_xxlarge. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def convnext_xxlarge(vision_tower_name, pretrained=False, **kwargs) -> ConvNeXt:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[49406,   320,  2402,  1957,   320,  9865,  7031,   537,   550, 12040,\n",
      "          6846,  6799,   269,   518,  6799,  3926, 12695,   267, 12609,   267,\n",
      "           537, 31497,  8692,   531,   518,  7031,   568,  3883,   269,  7031,\n",
      "           281, 10967,   589,  5766,  4717,   531,   518,  5694,   530,   585,\n",
      "           269,  6799,   281,   518,  1179,  3105,   593,   320,  5444,  9696,\n",
      "         19119,   537,  4305,   593,   320,  5992,  3246,   269,   518,  3608,\n",
      "           539,   320,  3718,  5751,   537,   518,  1179,  6766,   750, 10258,\n",
      "            13, 34308,   338,   285,  7031,   281,  2812,   525,   518,    80,\n",
      "           601,   267,  1781,   836,  3204,   781,   518,  4902,   267,  2046,\n",
      "           601,   518, 17464,   539,   518,  4914,   267,   518,  5906,   539,\n",
      "           518,  4914,   267,   537,   518, 12979,  4781,   267,  1033,   878,\n",
      "          4902,   533,  2881,   530,   589,  5766,   269,  6799,   281,   328,\n",
      "           880,  3675,   267,   767,   997,   533,   871,  4902,   530,   518,\n",
      "          5766,    13, 34308,   338,   285,  7031,   281,  2812,   525,   518,\n",
      "            80,   601,   267,  1781,   836,  3204,   781,   518,  1179,   267,\n",
      "          2046,   601,  1179, 14249,   537,  1179, 14793,   267,  1033,   878,\n",
      "          1179,   533,  2881,   530,   589,  5766,   269,  6799,   281,   518,\n",
      "          1179, 14249,   533, 23041,   269,   518,  1179, 14793,   631,   518,\n",
      "         23013,   537,   518,  3718,    13, 34308,   338,   285, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'pixel_values': tensor([[[[-0.4387, -0.7993, -0.5125,  ..., -0.6580, -0.6920, -0.6208],\n",
      "          [-0.7520, -0.8119, -0.6776,  ..., -0.7529, -0.7023, -0.8560],\n",
      "          [-0.7072, -0.7672, -0.6329,  ..., -0.7081, -0.6576, -0.8112],\n",
      "          ...,\n",
      "          [-0.4042, -0.2364, -0.3393,  ..., -0.3810, -0.3687, -0.3664],\n",
      "          [-0.2990, -0.3295, -0.3613,  ..., -0.3063, -0.2895, -0.3650],\n",
      "          [-0.3313, -0.3380, -0.3029,  ..., -0.4373, -0.3102, -0.4224]],\n",
      "\n",
      "         [[-0.4387, -0.7993, -0.5125,  ..., -0.6580, -0.6920, -0.6208],\n",
      "          [-0.7520, -0.8119, -0.6776,  ..., -0.7529, -0.7023, -0.8560],\n",
      "          [-0.7072, -0.7672, -0.6329,  ..., -0.7081, -0.6576, -0.8112],\n",
      "          ...,\n",
      "          [-0.4042, -0.2364, -0.3393,  ..., -0.3810, -0.3687, -0.3664],\n",
      "          [-0.2990, -0.3295, -0.3613,  ..., -0.3063, -0.2895, -0.3650],\n",
      "          [-0.3313, -0.3380, -0.3029,  ..., -0.4373, -0.3102, -0.4224]],\n",
      "\n",
      "         [[-0.4387, -0.7993, -0.5125,  ..., -0.6580, -0.6920, -0.6208],\n",
      "          [-0.7520, -0.8119, -0.6776,  ..., -0.7529, -0.7023, -0.8560],\n",
      "          [-0.7072, -0.7672, -0.6329,  ..., -0.7081, -0.6576, -0.8112],\n",
      "          ...,\n",
      "          [-0.4042, -0.2364, -0.3393,  ..., -0.3810, -0.3687, -0.3664],\n",
      "          [-0.2990, -0.3295, -0.3613,  ..., -0.3063, -0.2895, -0.3650],\n",
      "          [-0.3313, -0.3380, -0.3029,  ..., -0.4373, -0.3102, -0.4224]]]]), 'label': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  7031,\n",
      "           281,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  6799,   281,   518,  1179,  3105,   593,   320,  5444,  9696,\n",
      "         19119,   537,  4305,   593,   320,  5992,  3246,   269,   518,  3608,\n",
      "           539,   320,  3718,  5751,   537,   518,  1179,  6766,   750, 10258,\n",
      "            13, 34308,   338,   285,  7031,   281,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  6799,   281,   328,\n",
      "           880,  3675,   267,   767,   997,   533,   871,  4902,   530,   518,\n",
      "          5766,    13, 34308,   338,   285,  7031,   281,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "          -100,  -100,  -100,  -100,  -100,  -100,  -100,  6799,   281,   518,\n",
      "          1179, 14249,   533, 23041,   269,   518,  1179, 14793,   631,   518,\n",
      "         23013,   537,   518,  3718,    13, 34308,   338,   285, 49407, 49407,\n",
      "         49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407, 49407]])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from eagle.datasets.audio_dataset import AudioDataset\n",
    "audio_text_path = '/home1/hxl/disk/EAGLE/dataset/AudioSetCaps/example.csv'\n",
    "audio_path = \"/home1/hxl/disk/EAGLE/dataset/AudioSetCaps/example\"\n",
    "audio_pretrain_path = '/home1/hxl/disk/EAGLE/model/LanguageBind_Audio_FT'\n",
    "audio_dataset = AudioDataset(audio_text_path, audio_path, audio_pretrain_path, 200)\n",
    "# with open('try.txt', 'w') as out_txt:\n",
    "#     torch.set_printoptions(threshold=5000)\n",
    "#     out_txt.write(str(audio_dataset[0].input_ids[0][:200]) + '\\n')\n",
    "#     out_txt.write(str(audio_dataset[0].label[0][:200]))\n",
    "print(audio_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2137a94f-6617-45bb-b7ed-eb5b07852ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPooling(last_hidden_state=tensor([[[-0.5856,  0.7351, -0.1224,  ...,  0.4932,  0.9014,  0.4706],\n",
      "         [-0.3814,  1.6395, -0.0109,  ...,  0.9044,  0.8734,  0.3482],\n",
      "         [-0.0723,  1.3671, -1.0399,  ...,  1.0863,  1.0086, -0.2170],\n",
      "         ...,\n",
      "         [-0.5481,  1.1947, -0.3049,  ...,  0.7608,  1.3982,  0.4923],\n",
      "         [ 0.0300,  1.3293,  0.9402,  ...,  1.1437,  0.8907,  1.4946],\n",
      "         [-0.2692,  1.2994, -0.1924,  ...,  1.2060,  1.1643,  1.4888]]]), pooler_output=tensor([[-0.4626,  0.6386,  0.2438,  ...,  0.6074,  0.8556,  0.4010]]), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "from eagle.model.multimodal_encoder.audio_models.languagebind_audio import LanguageBindAudio\n",
    "model = LanguageBindAudio.from_pretrained(audio_pretrain_path)\n",
    "model.eval()\n",
    "data = audio_dataset[0]\n",
    "del data['label']\n",
    "with torch.no_grad():\n",
    "    out = model.vision_model(pixel_values=data.pixel_values)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "326ed208-2cf6-45d4-8c60-3381f9556d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4626,  0.6386,  0.2438,  ...,  0.6074,  0.8556,  0.4010]])\n"
     ]
    }
   ],
   "source": [
    "print(out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d835c8b-d04b-49cc-ac8e-7cb2dcb4db68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1, 1, 1, 2]]\n"
     ]
    }
   ],
   "source": [
    "a = [[0, 1, 1, 1, 2]]\n",
    "for i in a:\n",
    "    i[0] = 2\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e6ce18-bffe-41e5-a3ab-a954edaf25a2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': 'images/eagle-1.0-sft-id-0.jpg', 'conversations': [{'from': 'human', 'value': \"What's happening in the scene?\\n<image>\"}, {'from': 'gpt', 'value': 'The image showcases a white porcelain stein with a gold handle and a black lid. The stein is adorned with a vibrant design featuring two men dressed in traditional German attire. They are seated at a table covered with a blue tablecloth, each holding a beer stein in their hands. The stein is positioned against a white background and captured from a slight angle, allowing a clear view of its intricate details. The overall scene depicted on the stein appears to be a jovial gathering, a common theme in German beer culture. The image does not contain any discernible text. The relative positions of the objects and their interactions have been meticulously portrayed, contributing to the authenticity of the scene.'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "json_dict = json.load(open('/home1/hxl/disk/EAGLE/dataset/Eagle-1.8M/eagle-10.json'))\n",
    "print(json_dict[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a6deb9-420f-43af-8039-7d6ad480ee9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'from': 'human', 'value': \"What's happening in the scene?\\n<image>\"}, {'from': 'gpt', 'value': 'The image showcases a white porcelain stein with a gold handle and a black lid. The stein is adorned with a vibrant design featuring two men dressed in traditional German attire. They are seated at a table covered with a blue tablecloth, each holding a beer stein in their hands. The stein is positioned against a white background and captured from a slight angle, allowing a clear view of its intricate details. The overall scene depicted on the stein appears to be a jovial gathering, a common theme in German beer culture. The image does not contain any discernible text. The relative positions of the objects and their interactions have been meticulously portrayed, contributing to the authenticity of the scene.'}]]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "print(copy.deepcopy([json_dict[0][\"conversations\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095ec677-5365-4e4b-b81a-05a623798db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'from': 'human', 'value': \"What's happening in the scene?\\n<image>\"}, {'from': 'gpt', 'value': 'The image showcases a white porcelain stein with a gold handle and a black lid. The stein is adorned with a vibrant design featuring two men dressed in traditional German attire. They are seated at a table covered with a blue tablecloth, each holding a beer stein in their hands. The stein is positioned against a white background and captured from a slight angle, allowing a clear view of its intricate details. The overall scene depicted on the stein appears to be a jovial gathering, a common theme in German beer culture. The image does not contain any discernible text. The relative positions of the objects and their interactions have been meticulously portrayed, contributing to the authenticity of the scene.'}]]\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "srcs = copy.deepcopy([json_dict[0][\"conversations\"]])\n",
    "def print_dict(src: Sequence[str]):\n",
    "    print(src)\n",
    "print_dict(srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1865b-67dd-46f9-a6fa-3e5e6f37708c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
